---
layout: post
title: "读书笔记-数理统计学简史"
description: "数理统计学简史"
category: 数学
tags: [统计学]
---
{% include JB/setup %}

读[《数理统计学简史》](http://book.douban.com/subject/1522839/)。

![zen](http://img5.douban.com/lpic/s26036597.jpg)

##第一章 早期概率论——从萌芽到《推测术》
我们把可重复事件的慨率称为客观的,而一次性事件的概率称为主观的.`客观概率`的决定有一定的、公认的法则可凭,不随人的主现意志转移。`主观概率`则取决人的主观看法,没有一个公认的方法可决定一个惟一的值。主观概率可以反映一种信仰。

客观概率有两种形式,第一种是依据该事件在试验大量重复中出现的频率，另一种形式是试验的可能结果只有有限个,且根据对称性的考虑.任一种可能结果都没有比另外结果占优势的地方,于是只能认为各结果有同等出现的机会(等可能性)。若总的可能结果有N个,而某一事件包含其中的M个结果,则该事件的概率为M/N。这种方式定义的概率现今叫做`古典概率`(与此相对,第一种方式定义的概率叫做`统计概率`).

1933年苏联大数学家柯尔莫哥洛夫(A. H. Kolm.ogorov，1903-1987) 制定了概率论的公理体系。

主观概率和客观概率在数理统计学中都有重要地位,前者是数理统计学中的贝叶斯学派的基础，后者则迄今仍占领了数理统计学的大部分阵地(称为频率学派)。

1. 卡丹诺的著作
    * 其在概率史上的地位,是因为他有一本名叫《机遇博弈》的著作(英译书名 The Book of Games of Chance)。
    * 明确指出骰子应为“诚实的”(honest)，意指6面中各面都有同等机会出现。多个诫实的骰子技掷结果有同等机会,并明确定义胜率是有利结果数与不利结果数之比。
    * 对"频率逼近概率"这一后来被伯努利称之为"笨人皆知"的事实,尚无所认识。
2. `分赌本问题`
    * A，B二人赌博,各出注金a元。每局各人获胜概率都是1/2,约定:谁先胜S局，即赢得全部注金2a元，现进行到A胜S1局、B胜S2局(S1和S2都小于S)的时赌博因故停止,问此时注金2a应如 何分配给A和B才算公平?
    * 这个问题的症结在于：它关乎各人在当时状况下的[期望][1]值。
    * 假定赌博继续进行下去，至多再赌`\(r=r_1+r_2-1\)`局，即分出胜负。若A获胜，他在这r局中至少须获胜`\(r_1\)`局。按二项分布A取胜的概率为`\(\sum_{i=r_1}^r{r \choose i}2^{-r}\)`,`\(p_B=1-p_A\)`(J注1)
    * 注金应按`\(p_A:p_B\)`分配给A和B。而`\(2ap_A\)`和`\(2ap_B\)`是A、B在当时状态下的期望值。
    * 此解是帕斯卡在1654年提出。
3. 帕斯卡与费尔马的通信
    * 引进了赌博的值(value)的概念，值等于赌注乘以获胜概率。3年后，惠更斯改“值”为“`期望`”(expectation)。
    * 分赌本问题之帕斯卡解法：以`\(r_1\)`和`\(r_2\)`分别记为取得胜利，A、B尚须赢得的赌局数。若赌博继续下去，A(以及B)最终取得的概率，只与`\(r_1\)`和`\(r_2\)`有关。记此概率为`\(e(r_1,r_2)\)`，则有边界条件：
        * `\(e(0,r_2)=1,当r_2>0\)`
        * `\(e(r_1,0)=0,当r_1>0\)`
        * `\(e(a,a)=\frac{1}{2}\)`,(1)
        * 且成立递推公式`\(e(r_1,r_2)=\frac{e(r_1-1,r_2)+e(r_1,r_2-1)}{2}\)`(2)
        * 在此用了[全概率公式][2]，即考虑再赌一局，有“A胜”、“B胜”两种可能。由(1)(2)出发，递推可得到一般形式`\(e(r_1,r_2)=\sum_{i=0}^{r_2-1}C_i^{r_1+r_2-1}2^{-(r_1+r_2-1)}\)`(3)
    * 分赌本问题之费马尔解法：不妨设`\(r_1<r_2\)`，为A最终获胜，所再赌的局数可能为`\(r_1,r_1+1,...,r_1+r_2-1\)`（完备事件群），期间B取胜的局数`\(i=0,1,...,r_2-1\)`，若B胜i局，则到A最终取胜止再胜`\(r_1+i\)`局，其中前`\(r_1+i-1\)`局中A胜`\(r_1-1\)`局，而第`\(r_1+i\)`局为A胜。
        * 这事件的概率为`\(C_{r_1-1}^{r_1-1+i}2^{-(r_1+i-1)}·2^{-1}=C_{r_1-1}^{r_1+1+i}2^{-(r_1+i)}\)`，这里用到了[二项式定理][3]和`概率乘法`(J注2)。
        * 对`\(i=0,1,...,r_2-1\)`相加得`\(e(r_1,r_2)=\sum_{i=0}^{r_2-1}C_{r_1-1}^{r_1-1+i}2^{-(r_1+i)}\)`，这里隐含使用了`概率加法`(J注3)。
4. 惠更斯的《机遇的规律》
    * 《机遇的规律》出版于1657年，在欧洲作为概率论的标准教材长达50年。
    * 据惠更斯的命题不难证明：若某人在赌博中分别以概率`\(p_1,...,p_k(p_1+...+p_k=1)\)`得`\(a_1,...,a_k\)`元，则其期望为`\(p_1a_1+...+p_ka_k\)`。即离散随机变量的期望定义。
5. 《推测术》前三部分内容提要
    * 伯努利写《推测术》这一著作是在他生命的最后两年。在1705年他去世时，此书尚未整理定稿。
    * 《推测术》的前三部分，是古典概率的系统化和深化。着重指导计算的一般规律及其数学证明，并以数字实例来解释其应用。这已与现代编写教科书的模式相符合。
    * 明确指出了独立情况下概率乘法定理的表现形式，在此基础上严格证明了二项概率公式`\(C_i^np^iq^{n-i}\)`。开创了通过无穷级数求和计算概率的方法。
    * 首次引进了“排列”的概念，证明了n个相异物件的不同排列数为n!，而n个中取r个排列的不同排列数为n(n-1)···(n-r+1)。也得出了n物件不全相异时排列数公式。在组合方面，研究了组合系数的性质，可以重复的组合数，超几何分布，特别是正整数幂次和的表达式:
        * `\(\sum_{i=1}^ni^m=\frac{n^{m+1}}{m+1}+\frac{n^m}{2}+\sum_{i=1}^{m/2}\frac{B_{2i}C_{2i-1}^mn^{m-2i+1}}{2i}\)`
        * `\(B_{2i}\)`叫`伯努利常数`，其最初几个值为`\(B_2=\frac{1}{6},B_4=-\frac{1}{30},B_6=\frac{1}{42},B_8=-\frac{1}{30}\)`
        * 由此式归纳定义出`\(\frac{1}{2}=\frac{1}{2k+1}+\sum_{i=1}^k\frac{1}{2i}B_{2i}C_{2i-1}^{2k},k=1,2,...\)`
6. 伯努利关于概率的几点看法
    * 把客观概率明确区分为两类
        * “可以先验地计算”的概率(古典概率，这里“先验”与贝叶斯统计中“先验”意义不同)
        * “后验地计算”的概率(通过大量观察的结果去计算)
    * 对事物采取了一种机械决定论的观点。世界上的一切事物都受到了严格的因果律的支配。对于掷骰子，若把一切有关条件，包括骰子形状大小、质量分布、投掷的初始位置、外界条件等全弄准了了，则投掷结果也就决定了。
    * 引进所谓“道德确定性”(moral certainty)。一个事件，虽不能确然断定其会发生，但它若被认为以极大的可能性以至几乎不会不发生，就称它有道德确定性。即概率接近1的事件。现今我们把伯努利的道德确定性叫做“事实上的确定性”(practical certainty)。
    * 把古典概率中“等可能性”的思想推广到主观概率的场合。如果没有任何理由可以认为众多可能性中的某一个或某一些比其他可能性更具优势时，应给予这些可能性以同等的主观概率。
        * 例如，当我对A、B两位棋手的棋艺一无所知时，我对“A强于B”及“B强于A”这两种情况同给予主观概率1/2.
        * 后世称之为`“同等无知原则”`。统计学中的贝叶斯学派基于这一思想。
7. 伯努利大数定律
    * 缶中抽球的例子：缶中有a白球，b黑球，p=a/a+b，有放回地从缶中抽球N次，记录得到白球的次数为X，以X/N去估计p。
    * 伯努利企图证明用X/N估计p可以达到事实上的确定性(道德确定性)，即`\(\forall \epsilon>0,\eta>0,P(|\frac{X}{N}-p|>\epsilon)<\eta\)`
    * 取`\(\epsilon=(a+b)^{-1}\)`，这样做是把白、黑求扩充为ra和rb，p不变。只要取r足够的大，可使此数任意小。
    * 要证的是，对任给c>0，只须抽取次数N足够大，可使`\(P(|\frac{X}{N}-p|≤\epsilon)>cP(|\frac{X}{N}-p|>\epsilon)\)`(8)
    * 由(8)得`\(P(|\frac{X}{N}-p|>\epsilon)<(c+1)^{-1}\)`(9)(J注4)
    * X/P和p可以任意接近，一个更直截了当的提法`\(\lim_{n \to \infty}\frac{X}{N}=p\)`(10)
        * 这不可能实现，因为原则上不能排除“每次都抽到白球”的可能性，这时X/N总为1，不能收敛于p<1
        * 退一步：要求(10)式成立的概率为1，这个结论是对的。1909年由波莱尔证明。波莱尔的结论比伯努利强，故现今把他们的结论分别称为[强大数律][5]和[弱大数律][4]。
    * 伯努利要求的比(9)要高，(9)只肯定了当取N充分大时，用X/N估计p可达到任意指定的精度`\(\epsilon\)`，而可靠度不小于`\(1-(c+1)^{-1}\)`。伯努利希望弄清楚到底需要N多大。他证明了以下结果：
        * `\(m_1=不小于\frac{log[c(b-1)]}{log(a+1)-loga}的最小整数\)`
        * `\(m_2=不小于\frac{log[c(a-1)]}{log(b+1)-logb}的最小整数\)`
        * `\(N_1=\frac{m_1(a+b)+b(a+b)(m_1-1)}{a+1}\)`
        * `\(N_2=\frac{m_2(a+b)+a(a+b)(m_2-1)}{b+1}\)`
        * 取N=max(N1,N2)能满足(9),其一为：`\(a=30,b=20(p=\frac{3}{5}),\epsilon=\frac{1}{50},c=1000\)`，用上述结果算出所需的次数N为25550
        * 伯努利证明(9)所作的概率估值，比根据切比雪夫不等式所作的要精细得多。
    * 哲学意义
        * 斯蒂格勒指出：伯努利证明了数学家不仅可以后验地认识世界，还可以用数学去估量他们的知识的限度。
        * 伯努利在结束《推测术》时就其结果的意义作如下表述：世间的一切事物都受到因果律的支配，而我们也注定会在种种极其纷纭杂乱的事象中认识到某种必然。
    
##第二章 棣莫弗的二项概率逼近
之前伯努利证明了：当N->∞时频率X/N依概率收敛于p。他试图解决如下问题：给定`\(\epsilon>0,c>0\)`(`\(\epsilon\)`很小，c很大)，为使事件`\(|\frac{X}{N}-p|≤\epsilon\)`的概率不小于`\(\frac{c}{c+1}\)`，试验次数N至少须达到多少，但伯努利提供的答案不够令人满意。

1. 棣莫弗的研究的动因
    * 1721年，亚历山大·喀明提出一个问题：A、B二人在某甲家赌博，每局A获胜的概率为p，B获胜的概率为q=1-p，赌N局，以X记A胜局数。约定：若X≥Np，则A付给甲X-Np元；若X<Np，这时N-X>Nq，则B付给甲(N-X)-Nq=Np-X元。问甲所得的期望值是多少？
    * 此期望值`\(D_N=E(|X-N_p|)=\sum_{i=1}^N|i-N_p|b(N,p,i)\)`，这里b(N,p,i)为二项概率`\(C_i^Np^i(1-p)^{N-i}\)`
    * `\(D_N=2Npqb(N,p.N_p)\)`(2)
    * 现在更一般的形式`\(D_N=2\mu qb(N,p,\mu),\mu=[N_p]+1\)`(3),[a]为不超过a的最大整数
    * 记`\(K_N=E(|\frac{X}{N}-p|)=\frac{D_N}{N}\)`,由(2)得`\(K_N=2pqb(N,p,N_p)\)`，容易证明`\(lim_{n \to \infty}b(N,p,N_p)=0\)`(4)，这个证明可用初等方法(斯特林公式未问世)
    * 由此得出`\(lim_{n \to \infty}K_N=0\)`，再由`\(P(|\frac{X}{N}-p|≥\epsilon)≤\epsilon^{-1}K_N\)`(J注:?)，即得`\(lim_{n \to \infty}P(|\frac{X}{N}-p|≥\epsilon)=0\)`，这就是[伯努利大数定律][6]。
2. 棣莫弗的初步结果
    * 假定N为偶数2m，概率p=1/2，记b(i)=b(2m,1/2,i),中心项与一个任意项之比为b(m)/b(m+d)
    * 当N->∞时，
        * `\(b(m) \thicksim 2.168\frac{(1-\frac{1}{N})^N}{\sqrt{N-1}}\)`(5)
        * `\(log(\frac{b(m)}{b(m+d)}) \thicksim (m+d-\frac{1}{2})log(m+d-1)+(m-d+\frac{1}{2})-2mlogm+log(\frac{m+d}{m})\)`(6)
3. 初步结果的改进与斯特林的联系
    * 斯特林作出了关于b(m)的两个级数表达式(1725)：
        * `\(b^2(m)=\frac{2}{\pi(2m+1)}(1+\frac{1}{4(m+\frac{3}{2})}+\frac{9}{32(m+\frac{3}{2})(m+\frac{5}{2})}+...)\)`(7)
        * `\(b^{-2}(m)=\pi m(1+\frac{1}{4(m+1)}+\frac{9}{32(m+1)(m+2)}+...)\)`(8)
        * 这是`\(\pi\)`这个符号首次被引进到这类公式中
    * (8)右边只取主项1，即得到`\(b(m) \thicksim \sqrt{\frac{2}{\pi N}}\)`(9)
    * (9)可以通过应用瓦里斯在1655年得到的无穷级数乘积结果`\(\lim_{n \to \infty}\sqrt{\frac{1}{2N+1}}\frac{2·4·6····2N}{1·3·5····2(N-1)}=\sqrt{\frac{\pi}{2}}\)`(10)，需注意`\(b(m)=\frac{1·3·5····(2m-1)}{2·4·6····2m}\)`
    * [斯特林公式][7](1730)
        * `\(m!=\sqrt{2\pi}m^{m+\frac{1}{2}}exp(-m+\frac{1}{12m}-\frac{1}{360m^3}+...)\)`(11)
        * 教科书上常见的形式`\(m! \thicksim \sqrt{2\pi}m^{m+\frac{1}{2}}e^{-m}\)`(12)
4. 积分形式`\(P_d\)`的近似公式
    * `\(P_d=P(|X-N_p|≤d)\)`
    * 1733进一步证明N->∞,`\(\frac{b(m+d)}{b(m)} \thicksim exp(-\frac{2d^2}{N})\)`(13)
    * (9)和(13)结合，`\(b(m+d) \thicksim \frac{2}{\sqrt{2\pi N}}e^{-\frac{2d^2}{N}}\)`(14)
    * 利用(14)，并近似地以定积分代替和，得`\(P_d=\sum_{i:|m-i|≤d}·b(i) \thicksim \frac{2}{\sqrt{2\pi N}}\sum_{i:|m-i|≤d}e^{-2(\frac{d}{\sqrt{N}})^2} \thicksim \frac{2}{\sqrt{2\pi}}\int_{-\frac{d}{\sqrt{N}}}^{\frac{d}{\sqrt{N}}} e^{-2x^2}\, dx=\frac{1}{\sqrt{2\pi}}\int_{-\frac{d}{\sqrt{N}}}^{\frac{d}{\sqrt{N}}} e^{-\frac{x^2}{2}}\, dx\)`(15)
    * 棣莫弗给出的不是(15)，而是其单边形式`\(\sum_{i:c_1\sqrt{N}≤m-i≤c_2\sqrt{N}}b(i) \thicksim \frac{1}{\sqrt{2\pi}}\int_{2c_1}^{2c_2} e^{-\frac{x^2}{2}}\, dx\)`(16)，这里-∞<c1<c2<∞,c1,c2有界但可与N有关。
    * 给定c>0。在(15)式中令`\(d=c\sqrt{N}\)`，得`\(P_{c\sqrt{N}}=P(|\frac{X}{N}-\frac{1}{2}|≤\frac{C}{\sqrt{N}}) \thicksim \frac{1}{\sqrt{2\pi}}\int_{2c_1}^{2c_2} e^{-\frac{x^2}{2}}\, dx\)`(17)
    * 拉普拉斯在1774年证明了`\(\frac{1}{\sqrt{2\pi}}\int_{2c_1}^{2c_2} e^{-\frac{x^2}{2}}\, dx=1\)`，由此式及(17)可知取c充分大，则对足够大的N，事件`\(|\frac{X}{N}-\frac{1}{2}|≤\frac{C}{\sqrt{N}}\)`的概率可任意接近于1。由于`\(\lim_{n \to \infty}\frac{C}{\sqrt{N}}=0\)`,由此推出对任给`\(\epsilon>0\)`,有`\(\lim_{n \to \infty}P(|\frac{X}{N}-\frac{1}{2}|≤\epsilon)=1\)`，即[伯努利大数定律][6]。
    * 把(15)(或更一般的形式(16))叫做[棣莫弗中心极限定理][8]。
5. 棣莫弗工作统计意义的讨论
    * (17)说明了：就“用频率估计概率”这个特例而言，观察值的算术平均(在此例即频率)的精度，与观察次数N的平方根`\(\sqrt{N}\)`成比例。棣莫弗也看出了`\(\sqrt{N}\)`这个量的特殊地位，他为此引进“模”(modulu)这个称呼。它被现在常用的概念[标准差][9]所取代了。
    * 他对数理统计最大影响是现今以他名字命名的中心极限定理。在他发现40年后，拉普拉斯建立了中心极限定理较一般的形式。
    * 他的出发点始终是：把p作为一个已知值，如何在数值上逼近概率b(N,p,i)和Pd，而不是把p看作未知，如何通过观察值X去对p进行推断。他无法回答：以p记生男孩的概率，现观察了20468个婴儿，发现男婴有10442，问根据这一数据，对p≤1/2的可能性作出评价。200年后波兰统计学家奈曼提出[区间估计][10]。
6. 二项定理的[泊松][11]逼近
    * 泊松在1838年提出`\(\lim_{N \to \infty}b(N,p,k)=e^{-\lambda}\frac{\lambda^k}{k!}, \lambda=\lim_{N \to \infty}N_p\)`(22)
    * 此公式适用于p很小，N很大而`\(N_p\)`不是很大时。棣莫弗公式则适用于p不太接近0、1的时候。

##第三章 贝叶斯方法
1. 贝叶斯及其传世之作
    * 《An essay towards solving a problem in the doctrine of chance》
    * `逆概率`指“求概率这个问题的逆问题”：已知事件的概率为p，可由之计算某种观察结果出现的概率如何？
2. 贝叶斯的问题提法
    * 贝叶斯的问题可表述为：设X服从[二项分布][12]`\(B(N,\theta)\)`，N已知而`\(\theta\)`未知。给定常数a，b，0≤a<b≤1，在得到观察值之后，要求条件概率`\(P(a≤\theta≤b|X)\)`。
    * 例如，为证明男婴的概率`\(\theta > \frac{1}{2}\)`，在所观察的N个出生婴儿中发现男婴X个，要由此计算`\(P(\frac{1}{2}<\theta≤1|X)\)`。
3. 贝叶斯假设
    * 要计算θ的条件分布，就必须知道θ的无条件分布——即在观察到X的值以前θ有如何分布？
    * “台球模型”：有一张矩形的台球桌，不妨设其长边为1.有甲乙两人，甲先向桌上抛一球，使此球落在桌面上任何一处有同等机会。记A的横坐标为θ，则由A服从台面上的均匀分布，可知θ服从[0,1]区间上的均匀分布R(0,1)。过A作一直线垂直于桌面的长边，它与长边之交点即为θ。然后甲再向台面上抛掷N个球(图中X)，每个球的位置服从台面上的均匀分布且各次抛掷独立，甲数清这N个球中，处在虚线左边的个数为X。甲把N和X两个数据告诉乙。甲要求乙依据N和X去估计θ落在一指定区间[a,b]内的概率。![1](/assets/2014-02-21-history-of-statistics/1.png)
    * 贝叶斯把“对θ之值一无所知”这一含义不精确的说法，通过这个模型的直观上的观照，数学化为θ有R(0,1)均匀分布这个确切陈述。后人把“θ有均匀分布R(0,1)”这一陈述称为`贝叶斯陈述`，也称为`“同等无知”假设`，θ的分布R(0,1)称为`先验分布`。即θ的`无条件分布`。
    * 费歇尔提出：若对θ一无所知，那么对θ的一个函数，例如`\(\theta^2\)`也应一无所知，故按贝叶斯假设，`\(\theta^2\)`也应该有均匀分布R(0,1)，这就与`\(\theta \sim R(0,1)\)`产生了矛盾。
4. 问题的解答
    * 由先验分布`\(\theta \sim R(0,1)\)`解得：
        * `\(P_\theta(事件出现X次)=C_X^N\theta^X(1-\theta)^{N-X}\)`
        * 按全概率公式`\(P(事件出现X次)=\int_{0}^{1} C_X^N\theta^X(1-\theta)^{N-X}\, d\theta=(N+1)^{-1},X=0,1,...,N\)`(1)
        * `\(P(a≤\theta≤b|事件出现X次)=\frac{P(a≤\theta≤b,事件出现X次)}{P(事件出现X次)}\)`(2)
        * `\(P(a≤\theta≤b,事件出现X次)=\int_{a}^{b} P_\theta(事件出现X次)\, d\theta=C_X^N\int_{a}^{b} \theta^X(1-\theta)^{N-X}\, d\theta\)`(3)
        * 由(1)-(3)得`\(P(a≤\theta≤b|事件出现X次)=\frac{\int_{a}^{b} \theta^X(1-\theta)^{N-X}\, d\theta}{\int_{0}^{1} \theta^X(1-\theta)^{N-X}\, d\theta}=(N+1)C_X^N\int_{0}^{1} \theta^X(1-\theta)^{N-X}\, d\theta\)`(4)
    * “贝叶斯相合性”(拉普拉斯1774年)
        * 设概率的真值为`\(\theta_0\)`，作N次试验，观察到事件出现`\(X_N\)`次，任给`\(\epsilon>0\)`，按公式(4)有`\(P(\theta_0-\epsilon≤\theta≤\theta_0+\epsilon|X_N)=(N+1)C_{X_N}^N\int_{\theta_0-\epsilon}^{\theta_0+\epsilon} \theta^{X_N}(1-\theta)^{N-X_N}\, d\theta\)`
        * 拉普拉斯证明：N->∞，上式右边收敛于1.这说明：只要试验次数N足够大，`\(\theta\)`将以任意接近于1的概率落在`\(\theta_0\)`的一个任意小的近旁。
5. 贝叶斯假设的另一种解释
    * 基于(1)式，此式对X取0,1,...,N，这N+1个可能值中的每一个给以等概率`\((N+1)^{-1}\)`，他认为这个结果是对θ“绝对一无所知”的一种合理解释，而这一假设，正是贝叶斯假设`\(\theta \sim R(0,1)\)`的直接后果。
6. 拉普拉斯的不充分推理原则
    * 如果一个问题中存在若干不同的原因(cause)`\(A_1,...,A_n\)`，则在没有理由认为其中哪一个特别有优势时，先验概率应各取1/n，即认为各有同等机会出现。
    * 在统计问题中，这里所说的不同的“cause”`\(A_1,...,A_n\)`可看作代表未知参数的不同的可能值，以E记在这种原因下可能产生的事件，拉普拉斯提出：`\(\frac{P(A_i|E)}{P(E|A_i)}\)`与i无关。
7. 贝叶斯统计学
    * 统计推断一般的模式是：样本X的分布或概率密度`\(f_\theta(x)\)`依赖于未知参数θ，只知道θ属于某一集合`\(\Theta\)`，但不知它取`\(\Theta\)`中的何值。统计推断的任务，就是依据所抽得的样本X去作出某种有关θ之值的论断，例如对θ的值作出估计，或判断θ是否落在`\(\Theta\)`的某个指定子集`\(\Theta_1\)`之内等。
    * `频率学派`其特点是把需要推断的参数θ视为固定的未知常数而样本X为随机的，其着眼点在样本空间，有关的概率计算都是针对X的分布，另一叫`贝叶斯学派`，其特点正好与上述相反，参数θ视为随机变量而样本X视为固定的，其着眼点在参数空间，重视的是参数θ的分布。
    * 估计二项分布概率θ的问题：
        * 频率学派：以X记事件在N次观察中出现的次数，用频率X/N估计θ，其与θ的接近程度，可以用方差`\(E(\frac{X}{N}-\theta)^2\)`去衡量，这求期望的运算是针对X的分布，θ始终看作固定，没有随机性。
        * 贝叶斯学派：对θ的了解是具有先验分布R(0,1)，经过样本X的信息加入后，把对θ的了解调整为[β分布][13]:`\((N+1)C_X^N\theta^X(1-\theta)^{N-X}\)`,对比图为![2](/assets/2014-02-21-history-of-statistics/2.png)

##第四章 最小二乘法
1. 从算术平均谈起
    * 设真值为a，则测量值`\(x_i\)`的误差为：`\(\epsilon_i=x_i-a,i=1,...,n\)`
    * 因为测量值应在真值附近，故一般来说，当a确为真值时，`\(|\epsilon_1|,...,|\epsilon_n|\)`倾向于取最小值。令`\(L(a)=\sum_{i=1}^n\epsilon_i^2=\sum_{i=1}^n(x_i-a)^2\)`。使L(a)达到最小的a值，正是`\(x_1,...,x_n\)`的算术平均`\(\bar{x}=\frac{\sum_{i=1}^nx_i}{n}\)`
    * 使误差平方和达到最小以寻求估计值的方法，就叫做[最小二乘法][14]。一般形式可表述为：`\(目标函数=\sum(观测值-理论值)^2\)`
2. 勒让德以前的有关研究
    * 天文和测地学中的一些数据分析问题可以描述为：有若干个我们想要估计其值的量`\(\theta_1,...,\theta_k\)`，另有若干个可以测量的量`\(x_0,...,x_k\)`，按理论这些量之间应有线性关系：`\(x_0+x_1\theta_1+...+x_k\theta_k=0\)`(2)
    * 设进行了n次观测，n≥k，在第i次观测中，`\(x_0,...,x_k\)`分别取值`\(x_{0i},...,x_{ki}\)`，按(2)有`\(x_{0i}+x_{1i}\theta_1+...+x_{ki}\theta_k=0,i=1,...,n\)`(3)
    * 欧拉和拉普拉斯对于解线性矛盾方程组都没有什么建树。勒让德的成功在于他从一个新的角度来看待这个问题，他不像上述诸人那样致力于找出几个方程(个数等于未知数的个数)再去求解，而是考虑误差在整体上的平衡，即不使误差过分集中在几个方程内，而是让它比较均匀地分布于各方程。这个考虑使他采用`\(\sum_{i=1}^n(x_{0i}+x_{1i}\theta_1+...+x_{ki}\theta_k)^2=最小\)`(5)
3. 勒让德发明最小二乘法
    * 最小二乘法最先出现于1805年他发表的一本题为《计算彗星轨道的新方法》的著作的附录
    * 他提到：使误差平方和达到最小，在各方程的误差之间建立了一种平衡，从而防止某一极端误差(对决定参数的估计值)取得支配地位，而这有助于揭示系统的更接近真实的状态。
    * 为实现(5)而对各`\(\theta_i\)`求偏导数形成的线性方程组(高斯称之为正则方程组)`\(\sum_{r=1}^ks_{rj}\theta_r+s_{0j}=0,j=1,...,k\)`(6),`\(s_{rj}=\sum_{i=1}^nx_{rj}x_{ji},r=0,1,...,k,j=1,...,k\)`
4. 测量子午线长的工作
5. 高斯的贡献
    * [高斯-马尔可夫定理][15]：从统计学的角度肯定了最小二乘估计的合法性。
    * 导出了残差平方的表达式，并证明了：[残差平方和][16]除以n-p，是误差方差的一个[无偏估计][17]。
    * 证明了残差平方和服从分布`\(\sigma^2\chi_{n-p}^2\)`，这里`\(\chi_{n-p}^2\)`是自由度n-p的[χ2分布][18]。
6. 其他方法
    * 如果一个统计方法受少量异常值的影响比较小，则称该方法具有`稳定性`(robustness)。
    * 最小二乘是一种稳健性较差的方法，原因在于其目标函数是误差的平方，是一个增长很快的函数。用一个增长比平方更慢的函数ρ去代替平方，这个想法最早由当代统计学家休伯(P.J.Huber)在1964年提出。他把这一想法用于估计一个位置参数θ的情况，即`\(x_i=\theta+e_i,1≤i≤n\)`,取定函数ρ，找出使函数`\(M(\theta)=\sum_{i=1}^n\rho(x_i-\theta)\)`达到最小的θ，记为`\(\tilde{\theta}\)`称为θ的[M估计][19]。

##第五章 误差与正态分布





----

###J注
1. 概率加法求多次二项分布，`\(p_A=\sum_{i=r_1}^r{r \choose i}p^{r_i}(1-p)^{r-r_i}\)`,其中p=0.5
2. 概率乘法，两个事件互相独立(A是否发生和B是否发生没有一点关系)。假如A、B互相独立，那么A、B同时发生的概率是P(A)×P(B)
3. 概率加法，两个事件互不相容(不能同时发生)。假如A、B不能同时发生，则A、B有其中有一个发生的概率是P(A)+P(B)
4. `\(y=(c+1)^{-1}\)`,c由0->+∞,y由1->0



[1]: http://science.scileaf.com/library/536
[2]: http://science.scileaf.com/library/793
[3]: http://science.scileaf.com/library/33
[4]: http://science.scileaf.com/library/1693
[5]: http://science.scileaf.com/library/1368
[6]: http://science.scileaf.com/library/256
[7]: http://science.scileaf.com/library/595
[8]: http://science.scileaf.com/library/1379
[9]: http://science.scileaf.com/library/206
[10]:http://science.scileaf.com/library/616
[11]:http://science.scileaf.com/library/83
[12]:http://science.scileaf.com/library/88
[13]:http://science.scileaf.com/library/84
[14]:http://science.scileaf.com/library/456
[15]:http://science.scileaf.com/library/1000
[16]:http://science.scileaf.com/library/585
[17]:http://science.scileaf.com/library/245
[18]:http://science.scileaf.com/library/87
[19]:http://science.scileaf.com/library/180
`\(\)`
