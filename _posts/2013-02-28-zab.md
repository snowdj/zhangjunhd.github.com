---
layout: post
title: "ZooKeeper's atomic broadcast protocol"
description: ""
category: tech
tags: [zookeeper, paxos, zab]
---
{% include JB/setup %}

## Background

Atomic broadcast can also be defined as a reliable broadcast that satisfies the following properties:

* __Validity__: If a correct process broadcasts a message, then all correct processes will eventually deliver it.
* __Uniform Agreement__: If a process delivers a message, then all correct processes eventually deliver that message.
* __Uniform Integrity__: For any message m, every process delivers m at most once, and only if m was previously broadcast by the sender of m.
* __Uniform Total Order__: If processes p and q both deliver messages m and m′, then p delivers m before m′ if and only if q delivers m before m′.

<!--break-->

## Crash-recovery system model

The system is a set of processes Π = {p1,p2,...,pN}, also referred to as `peers` in this report, that communicate by message passing, are each equipped with a stable storage device, and may crash and recover indefinitely many times.
    
A `quorum` of Π is a subset Q ⊆ Π such that |Q| > N/2. Any two quorums have a non-empty intersection.

Processes have two states: up and down. A process is down from a crash time point to the beginning of its recovery, and up from the beginning of a recovery until the next crash happens.

There is a bidirectional `channel` for every pair of processes in Π, which is expected to satisfy the following properties: 

* `integrity`, asserting that process pj receives a message m from pi only if pi has sent m; 
* `prefix`, stating that if process pj receives a message m and there is a message m′ that precedes m in the sequence of messages pi sent to pj, then pj receives m′ before m. 

To achieve these properties, ZooKeeper uses TCP – therefore FIFO – channels for communication.

In ZooKeeper’s crash-recovery model, if the primary process crashes, a new primary process needs to be elected. Since broadcast messages are totally ordered, we require at most one primary active at a time. So over time we get an unbounded sequence of primary processes ρ1ρ2 . . . ρe . . ., where ρe ∈ Π, and e is an integer called `epoch`, representing a period of time when ρe was the single primary in the ensemble. Process ρe precedes ρe′, denoted ρe ≺ ρe′, if e < e′.

`Transactions` are state changes that the primary propagates (“broadcasts”) to the ensemble, and are represented by a pair ⟨v,z⟩, where v is the new state and z is an identifier called `zxid`. Transactions are first proposed to a process by the primary, then delivered (“committed”) at a process upon a specific call to a delivery method.

## Core properties

Our system, ZooKeeper, requires the following properties to maintain the state of processes consistent:

* __Integrity__:If some process delivers ⟨v,z⟩, then some process has broadcast ⟨v,z⟩.
* __Total order__:If some process delivers ⟨v,z⟩ before ⟨v′,z′⟩, then any process that delivers ⟨v′,z′⟩must also deliver ⟨v,z⟩ before ⟨v′,z′⟩.
* __Agreement__:If some process pi delivers ⟨v,z⟩ and some process pj delivers ⟨v′,z′⟩, then either pi delivers ⟨v′,z′⟩ or pj delivers ⟨v,z⟩.

The three safety properties above guarantee that processes are consistent. However, we need to satisfy one more property to enable multiple changes in progress from a given primary. Since each state change is based on a previous state if the change for that previous state is skipped, the dependent changes must also be skipped. We call this property __primary order__, and we split it into two parts:

* __Local primary order__: If a primary broadcasts ⟨v, z⟩ before it broadcasts ⟨v′, z′⟩, then a process that delivers ⟨v′, z′⟩ must have delivered ⟨v, z⟩ before ⟨v′, z′⟩.
* __Global primary order__: Suppose a primary ρi broadcasts ⟨v, z⟩, and a primary
ρj ≻ ρi broadcasts ⟨v′, z′⟩. If a process delivers both ⟨v, z⟩ and ⟨v′, z′⟩, then it must deliver ⟨v, z⟩ before ⟨v′, z′⟩.

Finally, a primary has to guarantee that the state updates generated are consistent. A primary consequently can only start broadcasting in an epoch once it has delivered the transactions of previous epochs. This behavior is guaranteed by the following property:

* __Primary integrity__: If a primary ρe broadcasts ⟨v, z⟩ and some process delivers ⟨v′, z′⟩ which was broadcast by ρe′ ≺ ρe, then ρe must have delivered ⟨v′, z′⟩ before broadcasting ⟨v, z⟩.

## Atomic broadcast protocol
#### Definition
In Zab, there are three possible (non-persistent) states a peer can assume: `following`, `leading`, or `election`.  Whether a peer is a follower or a leader, it executes three Zab phases: (1) `discovery`, (2) `synchronization`, and (3) `broadcast`, in this order. Previous to Phase 1, a peer is in state `election`, when it executes a leader election algorithm to look for a peer to vote for becoming the leader. At the beginning of Phase 1, the peer inspects its vote and decides whether it should become a follower or a leader. For this reason, leader election is sometimes called Phase 0.

ZooKeeper clients are applications that use ZooKeeper services by connecting to at least one server in the ensemble. The client submits operations to the connected server, and if this operation implies some state change, then the Zab layer will perform a broadcast. If the operation was submitted to a follower, it is forwarded to the leader peer. If a leader receives the operation request, then it executes and propagates the state change to its followers. Read requests from the client are directly served by any ZooKeeper server. The client can choose to guarantee that the replica is up-to-date by issuing a sync request to the connected ZooKeeper server.

#### Phases of the protocol
__Phase 0: Leader election__  
Peers are initialized in this phase, having state election. No specific leader election protocol needs to be employed, as long as the protocol terminates, with high probability, choosing a peer that is up and that a quorum of peers voted for. After termination of the leader election algorithm, a peer stores its vote to local volatile memory. If peer p voted for peer p′, then p′ is called `the prospective leader` for p. Only at the beginning of Phase 3 does a prospective leader become an established leader, when it will also be `the primary` process. If the peer has voted for itself, it shifts to `state leading`, otherwise it changes to `state following`.

__Phase 1: Discovery__  
In this phase, followers communicate with their prospective leader, so that the leader gathers information about the most recent transactions that its followers accepted. The purpose of this phase is to discover the most updated sequence of accepted transactions among a quorum, and to establish a new epoch so that previous leaders cannot commit new proposals. The complete description of this phase is described in Algorithm 1.

At the beginning of this phase, a follower peer will start a leader-follower connection with the prospective leader. Since the vote variable of a follower corresponds to only one peer, the follower can connect to only one leader at a time. If a peer p is not in state leading and another process considers p to be a prospective leader, any leader-follower connection will be denied by p. Either the denial of a leader-follower connection or some other failure can bring a follower back to Phase 0.

__Phase 2: Synchronization__  
The Synchronization phase concludes the recovery part of the protocol, synchronizing the replicas in the ensemble using the leader’s up-dated history from the previous phase. The leader communicates with the followers, proposing transactions from its history. Followers acknowledge the proposals if their own history is behind the leader’s history. When the leader sees acknowledgements from a quorum, it issues a commit message to them. At that point, the leader is said to be established, and not anymore prospective. 

__Phase 3: Broadcast__  
If no crashes occur, peers stay in this phase indefinitely, performing broadcast of transactions as soon as a ZooKeeper client issues a write request. At the beginning, a quorum of peers is expected to be consistent, and there can be no two leaders in Phase 3. The leader allows also new followers to join the epoch, since only a quorum of followers is enough for starting Phase 3. To catch up with other peers, incoming followers receive transactions broadcast during that epoch, and are included in the leader’s set of known followers.

Since Phase 3 is the only phase when new state changes are handled, the Zab layer needs to notify the ZooKeeper application that it’s prepared for receiving new state changes. For this purpose, the leader calls `ready(e)` at the beginning of Phase 3, which enables the application to broadcast transactions. Algorithm 3 describes the phase.

__Fail detection and Fail-over__  
Phase 1, 2, and 3 are apparently asynchronous and do not take into account possible peer crashes. To detect failures, Zab employs periodic heartbeat messages between followers and their leaders. If a leader does not receive heartbeats from a quorum of followers within a given timeout, it abandons its leadership and shifts to state election and Phase 0. A follower also goes to Leader Election Phase if it does not receive heartbeats from its leader within a timeout.

__Zab protocol summary__  

   * CEPOCH = Follower sends its last promise to the prospective leader 
   * NEWEPOCH = Leader proposes a new epoch e'
   * ACK-E = Follower acknowledges the new epoch proposal
   * NEWLEADER = Prospective leader proposes itself as the new leader of epoch e' 
   * ACK-LD = Follower acknowledges the new leader proposal
   * COMMIT-LD = Commit new leader proposal
   * PROPOSE = Leader proposes a new transaction
   * ACK = Follower acknowledges leader proposal 
   * COMMIT = Leader commits proposal
   
![zab2](/assets/2013-02-28-zab/zab2.png)

#### Implementation by FLE

`Fast Leader Election (FLE)` is the name of the default leader election algorithm in the implementation. This algorithm employs an optimization: It attempts to elect as leader the peer that has the most up-to-date history from a quorum of processes. When such a leader is elected, in Phase 1 it will not need to communicate with followers to discover the latest history. Even though other leader election algorithms are supported by the implementation, in reality Phase 1 was modified to require that Phase 0 elects a leader with the most up-to-date history.

In practice, since FLE covers the discovery responsibility of Phase 1, this phase has been neglected in version 3.3.3 (and also 3.3.4) of ZooKeeper. There is no clear distinction between Phases 1 and 2 in the implementation, so we refer to the combination of both as Recovery Phase. This phase comes after Phase 0, and assumes that the leader has the latest history in a quorum. Figure 1 compares the implemented phases to Zab’s phases.

![zab1](/assets/2013-02-28-zab/zab1.png)

The implemented Recovery Phase resembles more Phase 2 than Phase 1. Followers connect to the leader and send their last zxid, so the leader can decide how to synchronize the followers’ histories. However, the synchronization is done differently than in Phase 2: Followers can abort some outstanding transactions upon receiving the TRUNC message or accept newer proposals from the leader upon receiving the DIFF message.

The purpose of this synchronization is to keep the replicas in a mutually consistent state. In order to do so, committed transactions in any replica must be committed in all other replicas, in the same order. Furthermore, proposed transactions that should not be committed anymore must be abandoned so that no peer commits them. Messages SNAP and DIFF take care of the former case, while TRUNC is responsible for the latter.

The main postcondition that Fast Leader Election attempts to guarantee for the subse- quent Recovery Phase is that the leader will have in its history all committed transac- tions. This is supported by the assumption that the peer with the most recent proposed transaction must have also the most recent committed transaction. For performing the synchronization, Recovery Phase assumes this postcondition holds. If, however, the postcondition does not hold, a follower might have a committed transaction that the leader does not have. In that situation, the replicas would be inconsistent, and Recovery Phase would not be able to bring the ensemble to a consistent state, since the synchro- nization direction is strictly from leader to followers. To achieve the postcondition, FLE aims at electing a leader with highest `lastZxid` among a quorum.



