---
layout: post
title: "Improving MapReduce Performance in Heterogeneous Environments"
description: ""
category: 
tags: [mapreduce, paper]
---
{% include JB/setup %}

paper review:[Improving MapReduce Performance in Heterogeneous Environments](http://www.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-183.pdf)

<!--break-->

##2 Background: Scheduling in Hadoop

* There is a single `master` managing a number of `slaves`.
* The input file, which resides on a distributed filesystem throughout the cluster, is split into evensized `chunks` replicated for fault-tolerance.
* Hadoop divides each MapReduce job into a set of `tasks`.
* Each chunk of input is first processed by a `map` task, which outputs a list of key-value pairs generated by a user-defined map function. Map outputs are split into buckets based on key. When all maps have finished, `reduce` tasks apply a reduce function to the list of map outputs with each key. 
* The goal of speculative execution is to minimize a job’s `response time`.

####2.1 Speculative Execution in Hadoop
When a node has an empty task slot, Hadoop chooses a task for it from one of three categories.

* First, any failed tasks are given highest priority.
* Second, non-running tasks are considered. For maps, tasks with data local to the node are chosen first.
* Finally, Hadoop looks for a task to execute speculatively.

To select speculative tasks, Hadoop monitors task progress using a `progress score` between 0 and 1.

* For a map, the progress score is the fraction of input data read.
* For a reduce task, the execution is divided into three phases, each of which accounts for 1/3 of the score:
  * The `copy` phase, when the task fetches map outputs.
  * The `sort` phase, when map outputs are sorted by key.
  * The `reduce` phase, when a user-defined function is applied to the list of map outputs with each key.
  * In each phase, the score is the fraction of data processed.
    * a task halfway through the copy phase has a progress score of 1/2 * 1/3 = 1/6
    * a task halfway through the reduce phase scores 1/3 + 1/3 + 1/2 * 1/3 = 5/6

####2.2 Assumptions in Hadoop’s Scheduler
Hadoop’s scheduler makes several implicit assumptions:

* Nodes can perform work at roughly the same rate.
* Tasks progress at a constant rate throughout time.
* There is no cost to launching a speculative task on a node that would otherwise have an idle slot.
* A task’s progress score is representative of fraction of its total work that it has done. Specifically, in a reduce task, the copy, sort and reduce phases each take about 1/3 of the total time.
*  Tasks tend to finish in waves, so a task with a low progress score is likely a straggler.
*  Tasks in the same category (map or reduce) require roughly the same amount of work.

##3 How the Assumptions Break Down
####3.1 Heterogeneity
Heterogeneity seriously impacts Hadoop’s scheduler. Because the scheduler uses a fixed threshold for selecting tasks to speculate, too many speculative tasks may be launched, taking away resources from useful tasks (assumption 3 is also untrue). Also, because the scheduler ranks candidates by locality, the wrong tasks may be chosen for speculation first. For example, if the average progress was 70% and there was a 2x slower task at 35% progress and a 10x slower task at 7% progress, then the 2x slower task might be speculated before the 10x slower task if its input data was available on an idle node.

####3.2 Other Assumptions
ssumption 3, that speculating tasks on idle nodes costs nothing, breaks down when resources are shared. For example, the network is a bottleneck shared resource in large MapReduce jobs. Also, speculative tasks may compete for disk I/O in I/O-bound jobs.

Assumption 4, that a task’s progress score is approximately equal to its percent completion, can cause incorrect speculation of reducers. In a typical MapReduce job, the copy phase of reduce tasks is the slowest, because it involves all-pairs communication over the network. Tasks quickly complete the other two phases once they have all map outputs. However, the copy phase counts for only 1/3 of the progress score. Thus, soon after the first few reducers in a job finish the copy phase, their progress goes from 1/3 to 1, greatly increasing the average progress.

Assumption 5, that progress score is a good proxy for progress rate because tasks begin at roughly the same time, can also be wrong. The number of reducers in a Hadoop job is typically chosen small enough so that they they can all start running right away, to copy data while maps run. However, there are potentially tens of mappers per node, one for each data chunk. The mappers tend to run in waves.

##4 The LATE Scheduler
The primary insight behind our algorithm is as follows: We always speculatively execute the task that we think will **finish farthest into the future**, because this task provides the greatest opportunity for a speculative copy to overtake the original and reduce the job’s response time. We call our strategy LATE, for Longest Approximate Time to End.

We estimate the progress rate of each task as `ProgressScore/T`, where T is the amount of time the task has been running for, and then estimate the time to completion as `(1 − ProgressScore)/ProgressRate`. 

To really get the best chance of beating the original task with the speculative task, we should also **only launch speculative tasks on fast nodes** – not stragglers. We do this through a simple heuristic – don’t launch speculative tasks on nodes that are below some threshold, `SlowNodeThreshold`, of total work performed (sum of progress scores for all succeeded and in-progress tasks on the node).

Finally, to handle the fact that speculative tasks cost resources, we augment the algorithm with two heuristics:

* A cap on the number of speculative tasks that can be running at once, which we denote `SpeculativeCap`.
* A `SlowTaskThreshold` that a task’s progress rate is compared with to determine whether it is “slow enough” to be speculated upon. This prevents needless speculation when only fast tasks are running.

In summary, the LATE algorithm works as follows:

* If a node asks for a new task and there are fewer than SpeculativeCap speculative tasks running:
  * Ignore the request if the node’s total progress is below `SlowNodeThreshold`.
  * Rank currently running tasks that are not currently being speculated by estimated time left.
  * Launch a copy of the highest-ranked task with progress rate below `SlowTaskThreshold`.
  
Finally, we note that unlike Hadoop’s scheduler, LATE does not take into account data locality for launching speculative map tasks, although this is a potential extension. We assume that because most maps are data-local, network utilization during the map phase is low, so it is fine to launch a speculative task on a fast node that does not have a local copy of the data. Locality statistics available in Hadoop validate this assumption.